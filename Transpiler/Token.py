'''
All valid token constants, string to token / keyword mapper, token groups, etc. defined in this file
'''
#Primitive types
TOKEN_IDENTIFER = 0
TOKEN_INT       = 1
TOKEN_FLOAT     = 2
TOKEN_CHAR      = 3

#Binary Operators (Identification starts from '20')
TOKEN_ADD = 20
TOKEN_SUB = 21
TOKEN_MUL = 22
TOKEN_DIV = 23
TOKEN_MOD = 24

#Comparision / Assignment (Identification starts from '30')
TOKEN_EQ       = 30
#Comparision
TOKEN_CMP_EQ   = 31
TOKEN_CMP_NEQ  = 32
TOKEN_CMP_GT   = 33
TOKEN_CMP_GTEQ = 34
TOKEN_CMP_LT   = 35
TOKEN_CMP_LTEQ = 36

#Symbols (Identification starts from '50')
TOKEN_SEMIC = 50
TOKEN_LPAREN = 51
TOKEN_RPAREN = 52
TOKEN_LBRACE = 53
TOKEN_RBRACE = 54

#Keywords (Identification starts from '60')
TOKEN_KEYWORD_VAR = 60
#Logical
TOKEN_KEYWORD_AND  = 61
TOKEN_KEYWORD_OR   = 62
TOKEN_KEYWORD_NOT  = 63
TOKEN_KEYWORD_IF   = 64
TOKEN_KEYWORD_ELIF = 65
TOKEN_KEYWORD_ELSE = 66
TOKEN_KEYWORD_WHILE = 67
TOKEN_KEYWORD_FOR = 68

#END OF FILE
TOKEN_EOF = 200

#Wrapper
class Token:
    '''
    Wrapper class for tokens generated by Lexer. Each 'Token' contains a value and its corresponding type
    '''
    def __init__(self, tokenValue, tokenType) -> None:
        self.tokenValue = tokenValue
        self.tokenType  = tokenType
    
    def __repr__(self) -> str:
        return f"{self.tokenValue}: {self.tokenType}"

#String to Token Value mapper
stringToTokenValue = {
    "+": TOKEN_ADD,
    #'-': handled in lex()
    "*": TOKEN_MUL,
    "/": TOKEN_DIV,
    "%": TOKEN_MOD,

    "=" : TOKEN_EQ,
    ">" : TOKEN_CMP_GT,
    "<" : TOKEN_CMP_LT,
    "==": TOKEN_CMP_EQ,
    "!=": TOKEN_CMP_NEQ,
    "<=": TOKEN_CMP_LTEQ,
    ">=": TOKEN_CMP_GTEQ,

    ";": TOKEN_SEMIC,
    "(": TOKEN_LPAREN,
    ")": TOKEN_RPAREN,
    "{": TOKEN_LBRACE,
    "}": TOKEN_RBRACE,

    #We have reached end of file, lexed all of it
    '\0': TOKEN_EOF
}

#Token value (specifically operators) to string [For Emitter]
tokenOperatorsToString = {
    TOKEN_ADD        : "+",
    TOKEN_SUB        : "-",
    TOKEN_MUL        : "*",
    TOKEN_DIV        : "/",
    TOKEN_MOD        : "%",
    TOKEN_CMP_EQ     : "==",
    TOKEN_CMP_NEQ    : "!=",
    TOKEN_CMP_LT     : "<",
    TOKEN_CMP_GT     : ">",
    TOKEN_CMP_LTEQ   : "<=",
    TOKEN_CMP_GTEQ   : ">=",
    TOKEN_KEYWORD_AND: "&&",
    TOKEN_KEYWORD_OR : "||",
    TOKEN_KEYWORD_NOT: "!"
}

#Keyword to token value mapper
keywordToTokenValue = {
    "var" : TOKEN_KEYWORD_VAR,
    "and" : TOKEN_KEYWORD_AND,
    "or"  : TOKEN_KEYWORD_OR,
    "not" : TOKEN_KEYWORD_NOT,
    "if"  : TOKEN_KEYWORD_IF,
    "elif": TOKEN_KEYWORD_ELIF,
    "else": TOKEN_KEYWORD_ELSE,
    "while": TOKEN_KEYWORD_WHILE,
    "for"  : TOKEN_KEYWORD_FOR
}

'''
Grouping tokens into a single variable according to their precedance for binary operations
Optimizing it so it doesnt have to check for multiple variables and can just use bitwise operators to solve precedance

Mainly used for parseCommonBinaryOperations in Parser.py
'''

#Not handled seperately
LOGICAL_GROUP     = (1 << TOKEN_KEYWORD_AND) | (1 << TOKEN_KEYWORD_OR)
COMPARISION_GROUP = (1 << TOKEN_CMP_EQ) | (1 << TOKEN_CMP_NEQ) | (1 << TOKEN_CMP_GT) |\
                    (1 << TOKEN_CMP_GTEQ) | (1 << TOKEN_CMP_LT) | (1 << TOKEN_CMP_LTEQ)
ARITHMETIC_GROUP  = (1 << TOKEN_ADD) | (1 << TOKEN_SUB)
TERM_GROUP        = (1 << TOKEN_MUL) | (1 << TOKEN_DIV) | (1 << TOKEN_MOD)

#Used in EvalTypes.py determineExprType function
COMPARISION_AND_LOGICAL_GROUP = COMPARISION_GROUP | LOGICAL_GROUP
'''
tokenInGroup: Takes a token type, checks if it belongs to a certain group, return boolean
'''
def tokenInGroup(token, group) -> int:
    return group & (1 << token)